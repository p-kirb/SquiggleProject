{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ont_fast5_api.fast5_interface import get_fast5_file\n",
    "import pandas as pd\n",
    "from Settings import *\n",
    "import LSTMAutoencoder\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - 00014eb4-4e2c-4087-ac24-57dea735b7b4\n",
    "\n",
    "2 - 601f7bc7-3c09-4a78-a9b7-097bddcde809\n",
    "\n",
    "3 - 1b6939ba-4a35-4696-bc6f-2ddb3368266e\n",
    "\n",
    "4 - 95c03c50-57a5-4092-9a5f-87182d06a12c\n",
    "\n",
    "5 - b6d8845b-3eec-42f6-9510-b8ba1fc1ec44\n",
    "\n",
    "\n",
    "1 <--> 2    90.1\n",
    "\n",
    "3 <--> 4    91.2\n",
    "\n",
    "4 <--> 5    95.9 or 90.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../../similar_testdata/similar_squiggles.fast5\"\n",
    "\n",
    "def loadReads():\n",
    "\n",
    "    print(\"reading squiggles file...\")\n",
    "    reads = []\n",
    "    ids = []\n",
    "    with get_fast5_file(filepath, mode=\"r\") as f5:\n",
    "        for read in f5.get_reads():\n",
    "            if read.read_id in subset:\n",
    "                raw_data = read.get_raw_data()\n",
    "                reads.append(raw_data)\n",
    "                ids.append(read.read_id)\n",
    "\n",
    "    return reads, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading squiggles file...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['00014eb4-4e2c-4087-ac24-57dea735b7b4',\n",
       " '1b6939ba-4a35-4696-bc6f-2ddb3368266e',\n",
       " '601f7bc7-3c09-4a78-a9b7-097bddcde809',\n",
       " '95c03c50-57a5-4092-9a5f-87182d06a12c',\n",
       " 'b6d8845b-3eec-42f6-9510-b8ba1fc1ec44']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squiggles, ids = loadReads()\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model_weights.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[39m=\u001b[39m LSTMAutoencoder\u001b[39m.\u001b[39mLSTM()\n\u001b[0;32m----> 2\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39;49mload(model_path))\n\u001b[1;32m      3\u001b[0m model\u001b[39m.\u001b[39meval()            \u001b[39m#setting model to \"predict mode\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:771\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    769\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 771\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    772\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    773\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    774\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    775\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    776\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:270\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    269\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 270\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    271\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    272\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/serialization.py:251\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model_weights.pt'"
     ]
    }
   ],
   "source": [
    "model = LSTMAutoencoder.LSTM()\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()            #setting model to \"predict mode\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding 0...\n",
      "Took 15.374706983566284s.\n",
      "embedding 1...\n",
      "Took 21.962628602981567s.\n",
      "embedding 2...\n",
      "Took 33.27038836479187s.\n",
      "embedding 3...\n",
      "Took 25.172276258468628s.\n",
      "embedding 4...\n",
      "Took 14.064485788345337s.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "stateHs = []\n",
    "stateCs = []\n",
    "for i in range(len(ids)):\n",
    "    print(f\"embedding {i}...\")\n",
    "    s = time.time()\n",
    "\n",
    "    x = torch.tensor(scaler.fit_transform(squiggles[i].reshape(-1, 1))).squeeze(-1)\n",
    "    x = x.type(torch.FloatTensor)\n",
    "\n",
    "\n",
    "    state_h = torch.zeros(1, hidden_size)\n",
    "    state_c = torch.zeros(1, hidden_size)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for value in x:\n",
    "            pred, (state_h, state_c) = model(value, (state_h, state_c))\n",
    "\n",
    "        \n",
    "    \n",
    "    stateHs.append(state_h.squeeze(0))\n",
    "    stateCs.append(state_c.squeeze(0))\n",
    "    print(f\"Took {time.time()-s}s.\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200])\n",
      "tensor([ 4.3052e-01, -3.2039e-01, -1.6582e-01, -1.1707e-01,  2.2227e+00,\n",
      "        -1.2730e-01,  2.3749e-02,  3.2955e+00, -2.2894e-02, -1.3308e-01,\n",
      "        -2.9422e-02, -9.1946e-02, -1.2397e-02, -3.9789e-02, -7.5253e-02,\n",
      "         8.0515e-02,  4.8371e-02,  1.8322e-01,  8.9089e-02,  1.2826e-02,\n",
      "        -1.2472e+00, -8.8285e-02, -8.8368e-02,  2.5516e-01,  1.6373e-01,\n",
      "         1.6692e-01, -1.4093e-01, -5.5305e-02,  5.3905e-01,  2.1881e-02,\n",
      "         2.8987e-01,  6.0362e-01,  1.1437e-01,  1.1387e-01, -1.1960e-02,\n",
      "         6.0928e-02, -3.9376e-01,  8.7013e-02,  9.3056e-02, -7.5721e-03,\n",
      "        -1.4006e-01,  7.6234e-02,  9.7582e-02, -4.3426e-02,  3.9312e-01,\n",
      "        -5.3653e-02, -1.3969e-01,  9.7933e-02,  9.6053e-02, -1.2181e+00,\n",
      "        -3.4187e-04, -6.9184e-02, -7.5671e-03, -8.3132e-02,  3.2274e-01,\n",
      "         7.0907e-02,  3.4215e-02,  4.7031e-01, -1.5769e-01, -1.2761e-01,\n",
      "         1.7540e-01, -5.2492e-02, -6.8880e-01, -4.2344e-02, -1.0023e-01,\n",
      "         1.4647e+00, -2.9742e-02,  1.7101e-02, -5.9295e-02,  1.2995e-01,\n",
      "         8.5842e-02, -7.8195e-03, -1.6287e-01, -3.9257e-02,  8.4559e-03,\n",
      "         2.2369e-02,  6.3276e-02, -2.1985e-01,  2.2747e-03, -1.5487e+00,\n",
      "        -5.1680e-03,  6.0582e-02, -6.6679e-02, -2.0745e-01, -4.2978e-01,\n",
      "        -1.1313e-04, -4.7378e-01, -1.6534e-02,  7.7423e-02,  5.5443e-01,\n",
      "         9.1807e-02, -9.6737e-02,  6.2596e-03,  2.3560e-02, -2.4004e-01,\n",
      "         1.2474e-01,  5.9775e-01,  2.2913e+00, -2.8395e-01,  8.7972e-01,\n",
      "        -1.2771e-01,  1.1450e-01,  6.9350e-02,  7.8567e-01,  8.3622e-02,\n",
      "        -5.9300e-02,  9.8596e-02, -2.1934e-01,  1.6593e-02, -1.7320e-03,\n",
      "        -3.1811e-01,  5.9061e-02, -1.6738e-02,  2.5991e-02, -1.0622e-01,\n",
      "        -2.7564e-01,  9.6862e-02, -1.4513e-02,  1.3566e-01, -1.2307e-02,\n",
      "        -2.2564e-01,  9.0845e-02,  4.1092e-02,  6.1462e-02,  6.4359e-02,\n",
      "        -7.7791e-02, -9.9713e-03,  1.9050e-03,  2.5449e-01, -1.4002e-01,\n",
      "         1.1526e-01,  7.1261e-03,  5.2325e-01,  6.0006e-02, -1.2455e-01,\n",
      "        -3.0908e-04,  4.2369e-01,  1.3455e-01,  5.3577e-02,  5.5182e-02,\n",
      "        -8.1962e-02, -6.3038e-02,  4.3144e-02, -2.5670e-02,  6.5245e-02,\n",
      "         4.4999e-02,  2.8347e-01, -4.3884e-02, -3.4102e-02,  3.0184e-02,\n",
      "        -3.2332e-02, -2.7425e-01, -1.9136e-03, -1.7358e-01,  3.0609e+00,\n",
      "         1.2557e-01, -1.7702e-01,  2.1721e-01,  3.2512e-02, -6.0782e-01,\n",
      "        -1.1936e+00,  3.8331e-01, -2.3813e-02, -1.2443e-01,  2.2787e-02,\n",
      "        -2.4487e-01,  1.9057e+00, -4.2274e-01, -1.0613e-02, -2.6977e-01,\n",
      "         1.1883e+00,  2.6709e-02,  3.1089e-02, -3.2948e-01, -1.2655e-01,\n",
      "        -1.4347e-01, -1.1763e+00,  1.2785e-01,  1.9459e-01, -6.5341e-02,\n",
      "        -6.8991e-01, -2.7745e-03,  2.6979e-01,  3.3040e-01, -1.2255e-01,\n",
      "        -1.1819e+01,  9.0373e-03,  1.0153e-01, -6.3097e+00, -8.5461e-02,\n",
      "        -9.6962e-03,  1.9280e-01, -1.1254e-01,  5.3225e-02,  2.0620e-01,\n",
      "        -2.0683e-01, -9.2294e+00,  4.1314e-01,  9.9241e-01,  5.8940e-01])\n"
     ]
    }
   ],
   "source": [
    "print(stateCs[1].shape)\n",
    "print(stateCs[1].squeeze(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similartiesH = {}\n",
    "similartiesC = {}\n",
    "\n",
    "for i in range(len(ids)):\n",
    "    innerDictH = {}\n",
    "    innerDictC = {}\n",
    "    for s in range(len(ids)):\n",
    "        if s != i:\n",
    "            innerDictH[ids[s]] = str(norm(stateHs[i]-stateHs[s]))\n",
    "            innerDictC[ids[s]] = str(norm(stateCs[i]-stateCs[s]))\n",
    "\n",
    "\n",
    "    similartiesH[ids[i]] = innerDictH.copy()\n",
    "    similartiesC[ids[i]] = innerDictC.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"hSimilarties.json\", \"w\") as file:\n",
    "    json.dump(similartiesH, file)\n",
    "\n",
    "with open(\"cSimilarties.json\", \"w\") as file:\n",
    "    json.dump(similartiesC, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
